#!/usr/bin/env python3

# A partitioning wrapper for mcd-recurse

# Copyright 2019 Peter Palfraader
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#

from typing import Any, Dict, List, Optional, Tuple, Union, Set

from abc import abstractmethod

import argparse
import collections
import datetime
import fcntl
import json
import os
import random
import requests
import shutil
import subprocess
import sys
import tempfile
import time

from pathlib import Path

import logging
def L(*args, sep=' '):
    return sep.join(str(a) for a in args)

import cgs
from cgs.tools import *

class Face:
    def __init__(self, vertices):
        self._vertices = vertices
        self._neighbors = []
        self._collected = False
        self._initial_region = None
        self._initial_bucket = None

    def __iter__(self):
        return self._vertices.__iter__()

    def __repr__(self):
        return "<Face>"

    def add_buddy(self, face):
        self._neighbors.append(face)

    def neighbors(self):
        return self._neighbors


    def set_initial_region(self, i):
        self._initial_region = i

    def get_initial_region(self):
        return self._initial_region


    def set_collected(self):
        self._collected = True

    def is_collected(self):
        return self._collected

    def set_initial_bucket(self, i):
        self._initial_bucket = i

    def get_initial_bucket(self):
        return self._initial_bucket

class McdPartition:
    MIN_BUCKET_SIZE = 100

    def __init__(self, generator: str = os.path.basename(sys.argv[0])):
        """
        Initialize and then run this tool.
        """
        format='%(asctime)s '+generator+' %(filename)s:%(lineno)d  %(levelname)s - %(message)s'
        logging.basicConfig(format=format, level=logging.INFO)
        self.generator = generator
        try:
            self.main()
        except KeyboardInterrupt:
            logging.info(L('Interrupted'))
            sys.exit(1)

    @staticmethod
    def prepare_obj(temp_dir: str, solution: cgs.Solution) -> str:
        """
        Prepare an obj file (a previous solution) for consumption by the solver programs.

        The name of the file is returned.
        """
        obj_fn = os.path.join(temp_dir, 'instance-%s-%s.obj'%(solution._instance.name, solution._solution_id))
        with open(obj_fn, "wt") as f:
            solution.to_obj(f)
        return obj_fn

    def parse_obj_faces(self, fn):
        """
        Parse the .obj file and return a face list.
        """
        vertices = []
        faces = []
        with open(fn, "rt") as f:
            for line in f:
                if line.startswith('v'):
                    line = line.rstrip()
                    parts = line.split()
                    parts.pop(0)
                    vertices.append((float(parts[0]), float(parts[1])))
                if line.startswith('f'):
                    line = line.rstrip()
                    parts = line.split()
                    parts.pop(0)
                    faces.append(Face([int(p)-1 for p in parts]))
        return (vertices, faces)

    def join_up_faces(self, faces):
        edges = {}
        for face in faces:
            for e in cyclic_pair_iterator(face):
                edges[e] = face

        for face in faces:
            for e in cyclic_pair_iterator(face):
                e = tuple(reversed(e))
                face.add_buddy(edges.get(e, None))

    def build_commandline_for_faceobj(self, in_obj_fn, out_fn):
        cmd = [self.args.solver]
        cmd += ['--improve', '0']
        cmd += ['--improve-time', str(self.args.initial_shuffle_time)]
        cmd += ['--max-time', str(self.args.initial_shuffle_time)]
        cmd += ['--obj-in']
        cmd += ['--full-obj']
        cmd += ['--face-obj']
        cmd += ['--start_hole_at_higher_degree_vertex_probability', '0.0']
        cmd += [in_obj_fn, out_fn]
        return cmd

    def get_faces(self, input_fn):
        """
        runs an instance of mcd-recurse to maybe shuffle things around a bit,
        but primarily create a facelist.
        """
        faces_fn = os.path.join(self.temp_dir, 'faces.obj')
        cmd = self.build_commandline_for_faceobj(input_fn, faces_fn)
        o = subprocess.check_output(cmd, stdin=None, shell=False)
        o = o.decode()
        face_obj = self.parse_obj_faces(faces_fn)
        self.join_up_faces(face_obj[1])
        return (o, *face_obj)

    @staticmethod
    def randomize_instance_coordinates(vertices):
        """randomly switch x and y and flip signs"""
        sign_1 = 1 if random.randint(0, 1) > 0 else -1;
        sign_2 = 1 if random.randint(0, 1) > 0 else -1;
        if random.randint(0, 1) > 0:
            vertices = [ (x*sign_1,y*sign_2) for x,y in vertices ]
        else:
            vertices = [ (x*sign_1,y*sign_2) for y,x in vertices ]
        return vertices

    def split_faces(self, vertices, faces):
        xmin = min([v[0] for v in vertices])
        xmax = max([v[0] for v in vertices])
        ymin = min([v[1] for v in vertices])
        ymax = max([v[1] for v in vertices])

        x_step = (xmax-xmin) / self.args.split
        y_step = (ymax-ymin) / self.args.split

        for f in faces:
            x = min([vertices[vidx][0] for vidx in f])
            y = min([vertices[vidx][1] for vidx in f])

            xi = int((x - xmin) // x_step)
            yi = int((y - ymin) // y_step)
            assert(0 <= xi < self.args.split)
            assert(0 <= yi < self.args.split)
            idx = yi * self.args.split + xi
            f.set_initial_region(idx)

        initial_buckets = []
        for face in faces:
            bucket = []
            if face.is_collected(): continue
            todo = collections.deque()
            todo.append(face)
            face.set_collected()
            while len(todo) > 0:
                f = todo.popleft()
                bucket.append(f)
                f.set_initial_bucket(len(initial_buckets))

                for n in f.neighbors():
                    if n is None: continue
                    if n.is_collected(): continue
                    if n.get_initial_region() != face.get_initial_region(): continue
                    todo.append(n)
                    n.set_collected()

            initial_buckets.append(bucket)

        for b in initial_buckets:
            if len(b) < self.MIN_BUCKET_SIZE:
                logging.info(L("Small bucket found with just", len(b), "faces.  Merging into neighbor"))

                target = None
                for face in b:
                    for n in face.neighbors():
                        if n is None: continue
                        if n.get_initial_bucket() != face.get_initial_bucket():
                            target = n.get_initial_bucket()
                            break
                    if target is not None: break
                if target is None: raise Exception("Did not find a neighboring bucket")
                for face in b:
                    face.set_initial_bucket(target)
                initial_buckets[target] += b
                b.clear()
        buckets = [b for b in initial_buckets if len(b) > 0]
        return buckets

    def setup_subproblems(self, vertices, buckets):
        subproblems = []
        first_subproblem = True
        for i, b in enumerate(buckets):
            p = {}

            p['in'] = os.path.join(self.temp_dir, 'subproblem-%03d-in.obj'%(i,))
            p['out'] = os.path.join(self.temp_dir, 'subproblem-%03d-out.obj'%(i,))
            idxmap = {}
            edgeset = set()
            with open(p['in'], "wt") as f:
                for face in b:
                    for e in cyclic_pair_iterator(face):
                        for v in e:
                            if v in idxmap: continue
                            print("v", vertices[v][0], vertices[v][1], 0, file=f)
                            idxmap[v] = len(idxmap) + 1
                        print("l", idxmap[e[0]], idxmap[e[1]], file=f)
                        edgeset.add(tuple(sorted(e)))
            if (len(idxmap) - len(edgeset) + len(b) != 1):
                raise Exception("Prepared input is not simple!")

            cmd = []
            if self.args.sge is not None:
                if not self.args.sge_first_local or not first_subproblem:
                    #p['stdout_fn'] = os.path.join(self.temp_dir, 'subproblem-%03d.stdout'%(i,))
                    #p['stderr_fn'] = os.path.join(self.temp_dir, 'subproblem-%03d.stderr'%(i,))
                    #cmd += ['qsub', '-sync', 'y', '-N', self.generator, '-t', '1', '-q', self.args.sge, '-e', p['stderr_fn'], '-o', p['stdout_fn'], '-b', 'y']
                    cmd += ['/opt/gridengine/bin/linux-x64/qrsh', '-now', 'no', '-N', self.generator, '-q', self.args.sge, '-b', 'y']
                first_subproblem = False

            cmd += [self.args.solver]
            cmd += ['--improve', '0']
            cmd += ['--improve-time', str(self.args.max_child_time)]
            cmd += ['--max-time', str(self.args.max_child_time)]
            cmd += ['--obj-in']
            cmd += ['--full-obj']
            cmd += ['--face-obj']
            cmd += [p['in'], p['out']]
            logging.info(L("command will be", cmd))

            p['map'] = {v: k for k, v in idxmap.items()}
            p['cmd'] = cmd
            subproblems.append(p)
        return subproblems


    @staticmethod
    def run_subproblem(args):
        wait_after, p = args
        try:
            o = subprocess.check_output(p['cmd'], stdin=None, shell=False)
            if wait_after:
                time.sleep(30) # for NFS to sync, because reasons
            return o
        except subprocess.CalledProcessError as e:
            if 'stderr_fn' in p:
                with open(p['stderr_fn'], "r") as f:
                    shutil.copyfileobj(f, sys.stderr)
                sys.stderr.flush()
            raise e
        return ''

    def run_subproblems(self, subproblems):
        from multiprocessing import Pool
        outputs = []
        if self.args.sge is not None:
            processes = len(subproblems)
        else:
            processes = None # use default
        with Pool(processes=processes) as pool:
            wait_after = (self.args.sge is not None)
            args = [(wait_after, p) for p in subproblems]
            for i,o in enumerate(pool.imap_unordered(self.run_subproblem, args)):
                p = subproblems[i]
                p['stdout'] = o.decode()
                if 'stdout_fn' in p:
                    p['stdout'] = open(p['stdout_fn'], "rt").read()

    @staticmethod
    def parse_output(o):
        res = {}
        for line in o.splitlines():
            line = line.rstrip()
            a = line.split(':', 1)
            if len(a) <= 1: continue
            key, value = a
            if key == 'version':
                assert('version' not in res or res['version'] == value)
                res['version'] = value
            elif key == 'run_time': res[key] = float(value)
            elif key == 'num_iters': res[key] = int(value)
            elif key == 'num_cvx_areas': res[key] = int(value)
        return res

    @staticmethod
    def coalesce_outputs(initial_split_output, outputs):
        res = McdPartition.parse_output(initial_split_output)
        res['num_split_iters'] = res['num_iters']
        res['num_cvx_areas'] = 0
        res['num_child_iters'] = 0
        del res['num_iters']
        for o in outputs:
            for key, value in McdPartition.parse_output(o).items():
                if key == 'version':
                    assert(res['version'] == value)
                elif key == 'num_iters': res['num_child_iters'] += value
                elif key in ('run_time', 'num_cvx_areas'):
                  res[key] += value
        return res

    def join_objs(self, subproblems):
        edges = set()
        for p in subproblems:
            _, faces = self.parse_obj_faces(p['out'])
            for face in faces:
                for e in cyclic_pair_iterator(face):
                    s = sorted( (p['map'][e[0]+1], p['map'][e[1]+1]) )
                    edges.add( (s[0], s[1]) )
        return edges

    def run(self):
        """
        Run a given instance.
        """
        logging.info(L("Getting face-based obj (and maybe shuffling for a minute)"))
        get_faces_output, vertices, faces = self.get_faces(self.args.input_obj)
        vertices = self.randomize_instance_coordinates(vertices)
        buckets = self.split_faces(vertices, faces)

        subproblems = self.setup_subproblems(vertices, buckets)
        self.run_subproblems(subproblems)
        metadata = self.coalesce_outputs(get_faces_output, [p['stdout'] for p in subproblems])
        metadata['splits'] = len(buckets)
        edges = self.join_objs(subproblems)
        with open(self.args.output_obj, "wt") as f:
            for e in edges:
                print("l", e[0]+1, e[1]+1, file=f)
        for k, v in metadata.items():
            print("%s:"%(k,), v)
            logging.info(L("%s:"%(k,), v))

    def main(self):
        """
        Parse the command line and launch the solver
        """
        parser = argparse.ArgumentParser(description='cgshop2020 wrapper for '+self.generator)
        parser.add_argument("--url", dest="url", default=None)
        parser.add_argument("--api-key", dest="apikey")
        parser.add_argument("--no-ssl-check", dest="nosslcheck", action="store_true", help="Disable SSL certificate checks")
        parser.add_argument("--proxy", dest="proxy", help="set proxy (e.g. socks5://localhost:1080/)")

        parser.add_argument('--max-size', dest='max_size', type=int)
        parser.add_argument('--min-size', dest='min_size', type=int)

        parser.add_argument('--initial-shuffle-time', dest='initial_shuffle_time', default=60, type=int, help='How much time to spend on the initial shuffle')

        parser.add_argument("--verbose", dest="verbose", action="store_true", default=False, help='verbose')
        parser.add_argument('--sge', dest='sge', type=str, help='run childs via gridengine queue')
        parser.add_argument('--sge-first-local', dest='sge_first_local', action='store_true', default=False, help='run one child locally')

        parser.add_argument('--max-child-time', dest='max_child_time', type=int, default=1800, help='how long to work on each child')
        parser.add_argument('--split', dest='split', type=int, default=2, help='how many splits per dimension')

        parser.add_argument('solver', type=str)
        parser.add_argument('input_obj')
        parser.add_argument('output_obj')

        self.args = parser.parse_args()
        if self.args.verbose:
            logging.setLevel(logging.DEBUG)

        self.db = cgs.InstanceDatabase(
            url        = self.args.url,
            nosslcheck = self.args.nosslcheck,
            proxy      = self.args.proxy,
            apikey     = self.args.apikey)

        prefix = "%s-"%(self.generator, )
        if self.args.sge is not None:
            prefix = os.path.join(os.getcwd(), prefix)
        self.temp_dir = None
        try:
            self.temp_dir = tempfile.mkdtemp(prefix=prefix)
            self.run()
        finally:
            if self.temp_dir is not None:
                shutil.rmtree(self.temp_dir)


if __name__ == "__main__":
    McdPartition()
